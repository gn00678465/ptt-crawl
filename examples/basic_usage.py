#!/usr/bin/env python3
"""
PTT Stock çˆ¬èŸ²åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹

æ­¤ç¯„ä¾‹å±•ç¤ºæœ€åŸºæœ¬çš„ä½¿ç”¨æ–¹å¼ï¼Œé©åˆåˆæ¬¡ä½¿ç”¨è€…å­¸ç¿’ã€‚
åŒ…å«åŸºæœ¬çˆ¬å–ã€ç‹€æ…‹æŸ¥è©¢ã€è³‡æ–™åŒ¯å‡ºç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

from src.lib.config_loader import ConfigLoader
from src.lib.logging import setup_logging
from src.lib.redis_client import RedisClient
from src.repositories.article_repository import ArticleRepository
from src.services.crawl_service import CrawlService
from src.services.parser_service import ParserService
from src.services.state_service import StateService


async def basic_crawl_example():
    """åŸºæœ¬çˆ¬å–ç¯„ä¾‹"""
    print("ğŸš€ PTT Stock çˆ¬èŸ²åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹")
    print("=" * 50)

    # è¨­å®šæ—¥èªŒ
    setup_logging(level=logging.INFO)
    logger = logging.getLogger(__name__)

    try:
        # 1. åˆå§‹åŒ–æœå‹™
        print("\nğŸ“‹ æ­¥é©Ÿ 1: åˆå§‹åŒ–æœå‹™...")

        # è¼‰å…¥é…ç½®
        config_loader = ConfigLoader()
        config = await config_loader.load_config()

        # åˆå§‹åŒ– Redis å®¢æˆ¶ç«¯
        redis_client = RedisClient(
            url=config.get("REDIS_URL", "redis://localhost:6379"), retry_attempts=3, retry_delay=1.0
        )

        # åˆå§‹åŒ–å„é …æœå‹™
        state_service = StateService(redis_client=redis_client)
        parser_service = ParserService()
        article_repository = ArticleRepository(
            connection_string=config.get(
                "DATABASE_URL", "postgresql://ptt_user:password@localhost:5432/ptt_crawler"
            )
        )

        crawl_service = CrawlService(
            state_service=state_service,
            parser_service=parser_service,
            article_repository=article_repository,
            firecrawl_api_url=config.get("FIRECRAWL_API_URL", "http://localhost:3002"),
            firecrawl_api_key=config.get("FIRECRAWL_API_KEY"),
        )

        print("âœ… æœå‹™åˆå§‹åŒ–å®Œæˆ")

        # 2. æª¢æŸ¥ç³»çµ±ç‹€æ…‹
        print("\nğŸ“Š æ­¥é©Ÿ 2: æª¢æŸ¥ç³»çµ±ç‹€æ…‹...")

        # æ¸¬è©¦ Redis é€£ç·š
        redis_status = await redis_client.health_check()
        print(f"   Redis é€£ç·š: {'âœ… æ­£å¸¸' if redis_status['status'] == 'healthy' else 'âŒ ç•°å¸¸'}")

        # æ¸¬è©¦è³‡æ–™åº«é€£ç·š
        db_status = await article_repository.health_check()
        print(f"   è³‡æ–™åº«é€£ç·š: {'âœ… æ­£å¸¸' if db_status else 'âŒ ç•°å¸¸'}")

        if redis_status["status"] != "healthy" and not db_status:
            print("âŒ ç³»çµ±ç‹€æ…‹ç•°å¸¸ï¼Œè«‹æª¢æŸ¥é…ç½®")
            return

        print("âœ… ç³»çµ±ç‹€æ…‹æ­£å¸¸")

        # 3. åŸ·è¡ŒåŸºæœ¬çˆ¬å–
        print("\nğŸ” æ­¥é©Ÿ 3: åŸ·è¡ŒåŸºæœ¬çˆ¬å–...")
        print("   ç›®æ¨™: Stock æ¿")
        print("   åˆ†é¡: å¿ƒå¾—")
        print("   é æ•¸: 2 é ")

        result = await crawl_service.crawl_board(
            board="Stock",
            category="å¿ƒå¾—",
            pages=2,
            incremental=False,  # ä¸ä½¿ç”¨å¢é‡çˆ¬å–ï¼Œç²å–æœ€æ–°è³‡æ–™
            force=False,
        )

        # 4. é¡¯ç¤ºçˆ¬å–çµæœ
        print("\nğŸ“ˆ æ­¥é©Ÿ 4: çˆ¬å–çµæœæ‘˜è¦")
        print(f"   åŸ·è¡Œç‹€æ…‹: {result['status']}")
        print(f"   ç¸½åŸ·è¡Œæ™‚é–“: {result['duration']:.2f} ç§’")
        print(f"   çˆ¬å–æ–‡ç« æ•¸: {result['articles_crawled']} ç¯‡")
        print(f"   æ–°å¢æ–‡ç« æ•¸: {result['articles_saved']} ç¯‡")
        print(f"   éŒ¯èª¤æ•¸é‡: {result['errors_count']}")

        if result["errors_count"] > 0:
            print("   éŒ¯èª¤è©³æƒ…:")
            for error in result.get("errors", [])[:3]:  # åªé¡¯ç¤ºå‰ 3 å€‹éŒ¯èª¤
                print(f"     - {error}")

        # 5. æŸ¥è©¢çˆ¬å–ç‹€æ…‹
        print("\nğŸ“‹ æ­¥é©Ÿ 5: æŸ¥è©¢ Stock æ¿çˆ¬å–ç‹€æ…‹...")

        board_state = await state_service.get_board_state("Stock")
        if board_state:
            print(f"   æœ€å¾Œçˆ¬å–æ™‚é–“: {board_state.last_crawl_time}")
            print(f"   çˆ¬å–é æ•¸: {board_state.last_page_crawled}")
            print(f"   ç¸½æ–‡ç« æ•¸: {board_state.total_articles}")
            print(f"   æˆåŠŸç‡: {board_state.success_rate:.1%}")
        else:
            print("   æœªæ‰¾åˆ°çˆ¬å–ç‹€æ…‹è¨˜éŒ„")

        # 6. è³‡æ–™åŒ¯å‡ºç¯„ä¾‹
        print("\nğŸ’¾ æ­¥é©Ÿ 6: è³‡æ–™åŒ¯å‡ºç¯„ä¾‹...")

        # å¾è³‡æ–™åº«æŸ¥è©¢æœ€æ–°æ–‡ç« 
        latest_articles = await article_repository.get_articles_by_board(board="Stock", limit=5)

        if latest_articles:
            print(f"   æŸ¥è©¢åˆ° {len(latest_articles)} ç¯‡æœ€æ–°æ–‡ç« :")
            for i, article in enumerate(latest_articles, 1):
                print(f"     {i}. [{article.category}] {article.title[:30]}...")
                print(f"        ä½œè€…: {article.author} | æ™‚é–“: {article.publish_date}")

            # åŒ¯å‡ºç‚º JSON æª”æ¡ˆ
            import json

            output_file = Path("examples/output/basic_crawl_result.json")
            output_file.parent.mkdir(exist_ok=True)

            export_data = []
            for article in latest_articles:
                export_data.append(
                    {
                        "title": article.title,
                        "author": article.author,
                        "category": article.category,
                        "content": article.content[:200] + "..."
                        if len(article.content) > 200
                        else article.content,
                        "publish_date": article.publish_date.isoformat(),
                        "board": article.board,
                    }
                )

            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)

            print(f"   âœ… è³‡æ–™å·²åŒ¯å‡ºåˆ°: {output_file}")
        else:
            print("   æœªæ‰¾åˆ°æ–‡ç« è³‡æ–™")

    except Exception as e:
        logger.error(f"ç¯„ä¾‹åŸ·è¡Œå¤±æ•—: {e}")
        print(f"\nâŒ åŸ·è¡Œå¤±æ•—: {e}")

    finally:
        # æ¸…ç†è³‡æº
        if "redis_client" in locals():
            await redis_client.close()
        if "article_repository" in locals():
            await article_repository.close()

        print("\nğŸ¯ åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹åŸ·è¡Œå®Œæˆ")
        print("\nğŸ’¡ æç¤º:")
        print("   - æŸ¥çœ‹åŒ¯å‡ºçš„ JSON æª”æ¡ˆäº†è§£è³‡æ–™æ ¼å¼")
        print("   - å¯ä»¥ä¿®æ”¹çˆ¬å–åƒæ•¸ï¼ˆboardã€categoryã€pagesï¼‰")
        print("   - ä½¿ç”¨ incremental=True é€²è¡Œå¢é‡çˆ¬å–")
        print("   - æŸ¥çœ‹æ—¥èªŒæª”æ¡ˆäº†è§£è©³ç´°åŸ·è¡Œéç¨‹")


async def show_configuration_example():
    """é¡¯ç¤ºé…ç½®ç¯„ä¾‹"""
    print("\nâš™ï¸ é…ç½®ç¯„ä¾‹")
    print("-" * 30)

    print("1. åŸºæœ¬é…ç½® (é©åˆé–‹ç™¼ç’°å¢ƒ):")
    print(
        """
    DATABASE_URL=postgresql://ptt_user:password@localhost:5432/ptt_crawler
    REDIS_URL=redis://localhost:6379
    FIRECRAWL_API_URL=http://localhost:3002
    LOG_LEVEL=INFO
    CRAWL_RATE_LIMIT=60
    CRAWL_REQUEST_DELAY=1.5
    """
    )

    print("2. ç”Ÿç”¢ç’°å¢ƒé…ç½®:")
    print(
        """
    DATABASE_URL=postgresql://prod_user:secure_pass@prod_db:5432/ptt_crawler
    REDIS_URL=redis://prod_redis:6379
    FIRECRAWL_API_URL=https://api.firecrawl.dev
    FIRECRAWL_API_KEY=fc-your-api-key
    LOG_LEVEL=WARNING
    CRAWL_RATE_LIMIT=30
    CRAWL_REQUEST_DELAY=2.0
    """
    )


def show_common_commands():
    """é¡¯ç¤ºå¸¸ç”¨å‘½ä»¤ç¯„ä¾‹"""
    print("\nğŸ“ å¸¸ç”¨ CLI å‘½ä»¤ç¯„ä¾‹")
    print("-" * 35)

    commands = [
        ("åŸºæœ¬çˆ¬å–", "ptt-crawler crawl Stock --pages 3"),
        ("åˆ†é¡éæ¿¾", "ptt-crawler crawl Stock --category 'å¿ƒå¾—' --pages 5"),
        ("å¢é‡çˆ¬å–", "ptt-crawler crawl Stock --incremental"),
        ("åŒ¯å‡º JSON", "ptt-crawler crawl Stock --output json --output-file output.json"),
        ("åŒ¯å‡º CSV", "ptt-crawler crawl Stock --output csv --output-file output.csv"),
        ("ç³»çµ±ç‹€æ…‹", "ptt-crawler status"),
        ("çœ‹æ¿ç‹€æ…‹", "ptt-crawler status Stock"),
        ("æ¸…ç†ç‹€æ…‹", "ptt-crawler clean --states --older-than 30"),
        ("æŸ¥çœ‹é…ç½®", "ptt-crawler config show"),
        ("è¨­å®šé…ç½®", "ptt-crawler config set crawl.rate_limit 60"),
    ]

    for desc, cmd in commands:
        print(f"   {desc:12} : {cmd}")


if __name__ == "__main__":
    print("ğŸŒŸ æ­¡è¿ä½¿ç”¨ PTT Stock çˆ¬èŸ²å·¥å…·!")
    print("   æœ¬ç¯„ä¾‹å°‡æ¼”ç¤ºåŸºæœ¬çš„çˆ¬å–æµç¨‹")
    print("   è«‹ç¢ºä¿å·²æ­£ç¢ºå®‰è£å’Œé…ç½®æ‰€æœ‰ä¾è³´æœå‹™\n")

    # é¡¯ç¤ºé…ç½®å’Œå‘½ä»¤ç¯„ä¾‹
    show_configuration_example()
    show_common_commands()

    # è©¢å•æ˜¯å¦åŸ·è¡Œç¯„ä¾‹
    try:
        user_input = input("\næ˜¯å¦åŸ·è¡ŒåŸºæœ¬çˆ¬å–ç¯„ä¾‹? (y/N): ").strip().lower()
        if user_input in ["y", "yes", "æ˜¯"]:
            asyncio.run(basic_crawl_example())
        else:
            print("ğŸ‘‹ è¬è¬ä½¿ç”¨ï¼Œç¯„ä¾‹çµæŸ")
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ä½¿ç”¨è€…ä¸­æ–·ï¼Œç¯„ä¾‹çµæŸ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
