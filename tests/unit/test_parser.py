"""Unit tests for parser service.

Test PTT content parsing logic for articles and board pages.
"""
import pytest
from datetime import datetime
from typing import Dict, Any

from src.services.parser_service import ParserService


class TestParserService:
    """Test PTT content parsing functionality."""

    @pytest.fixture
    def parser_service(self) -> ParserService:
        """Create parser service instance."""
        return ParserService()

    @pytest.fixture
    def sample_article_response(self) -> Dict[str, Any]:
        """Sample Firecrawl API response for article parsing."""
        return {
            "success": True,
            "data": {
                "markdown": """# [å¿ƒå¾—] ä»Šæ—¥æŠ•è³‡å¿ƒå¾—åˆ†äº«

ä½œè€…: test_user
æ™‚é–“: Mon Sep 25 10:30:00 2024

ä»Šå¤©çš„å¸‚å ´è¡¨ç¾é‚„ä¸éŒ¯ï¼Œå°ç©é›»ä¸Šæ¼²äº†2%ã€‚
æˆ‘è¦ºå¾—é€™å€‹è¶¨å‹¢å¯èƒ½æœƒæŒçºŒä¸€æ®µæ™‚é–“ã€‚

å»ºè­°å¤§å®¶å¯ä»¥è€ƒæ…®é€¢ä½è²·é€²ã€‚

â€» ç™¼ä¿¡ç«™: æ‰¹è¸¢è¸¢å¯¦æ¥­åŠ(ptt.cc)
â€» æ–‡ç« ç¶²å€: https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html

æ¨ user1: æ„Ÿè¬åˆ†äº«
â†’ user2: åŒæ„é€™å€‹è§€é»
å™“ user3: ä¸åŒæ„""",
                "metadata": {
                    "title": "[å¿ƒå¾—] ä»Šæ—¥æŠ•è³‡å¿ƒå¾—åˆ†äº«",
                    "author": "test_user",
                    "publishTime": "Mon Sep 25 10:30:00 2024",
                    "board": "Stock",
                }
            }
        }

    @pytest.fixture
    def sample_board_response(self) -> Dict[str, Any]:
        """Sample board page response."""
        return {
            "success": True,
            "data": {
                "markdown": """# æ‰¹è¸¢è¸¢å¯¦æ¥­åŠ â€º Stock

1. [å¿ƒå¾—] ä»Šæ—¥æŠ•è³‡å¿ƒå¾—åˆ†äº« test_user
2. [æ¨™çš„] 2330 å°ç©é›»åˆ†æå ±å‘Š analyst_user
3. [è«‹ç›Š] æ–°æ‰‹æŠ•è³‡å»ºè­°æ±‚åŠ© newbie_user

[å¿ƒå¾—] æŠ•è³‡å¿ƒå¾—æ–‡ç« 
https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html

[æ¨™çš„] è‚¡ç¥¨åˆ†ææ–‡ç« 
https://www.ptt.cc/bbs/Stock/M.9876543210.A.456.html""",
                "links": [
                    {
                        "text": "[å¿ƒå¾—] æŠ•è³‡å¿ƒå¾—æ–‡ç« ",
                        "url": "https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html"
                    },
                    {
                        "text": "[æ¨™çš„] è‚¡ç¥¨åˆ†ææ–‡ç« ",
                        "url": "https://www.ptt.cc/bbs/Stock/M.9876543210.A.456.html"
                    }
                ]
            }
        }

    async def test_parse_article_success(self, parser_service: ParserService, sample_article_response: Dict[str, Any]):
        """Test successful article parsing."""
        url = "https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html"
        result = await parser_service.parse_article(sample_article_response, url)

        assert result is not None
        assert result["title"] == "[å¿ƒå¾—] ä»Šæ—¥æŠ•è³‡å¿ƒå¾—åˆ†äº«"
        assert result["author"] == "test_user"
        assert result["category"] == "å¿ƒå¾—"
        assert result["board"] == "Stock"
        assert "ä»Šå¤©çš„å¸‚å ´è¡¨ç¾" in result["content"]
        assert "â€» ç™¼ä¿¡ç«™" not in result["content"]  # Should be cleaned
        assert "æ¨ user1" not in result["content"]  # Comments should be removed

    async def test_parse_article_empty_content(self, parser_service: ParserService):
        """Test parsing article with empty content."""
        empty_response = {
            "success": True,
            "data": {
                "markdown": "",
                "metadata": {}
            }
        }

        url = "https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html"
        result = await parser_service.parse_article(empty_response, url)

        assert result is None

    async def test_parse_article_missing_required_fields(self, parser_service: ParserService):
        """Test parsing article missing title or author."""
        incomplete_response = {
            "success": True,
            "data": {
                "markdown": "Some content without proper title or author",
                "metadata": {}
            }
        }

        url = "https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html"
        result = await parser_service.parse_article(incomplete_response, url)

        assert result is None

    def test_extract_board_from_url(self, parser_service: ParserService):
        """Test board extraction from URLs."""
        test_cases = [
            ("https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html", "Stock"),
            ("https://www.ptt.cc/bbs/Gossiping/M.9876543210.A.456.html", "Gossiping"),
            ("https://www.ptt.cc/bbs/Tech_Job/M.1111111111.A.789.html", "Tech_Job"),
            ("invalid_url", "Unknown"),
        ]

        for url, expected_board in test_cases:
            board = parser_service._extract_board_from_url(url)
            assert board == expected_board

    def test_parse_title_with_category(self, parser_service: ParserService):
        """Test title parsing with category extraction."""
        test_cases = [
            ("# [å¿ƒå¾—] æŠ•è³‡å¿ƒå¾—åˆ†äº«", {"title": "[å¿ƒå¾—] æŠ•è³‡å¿ƒå¾—åˆ†äº«", "category": "å¿ƒå¾—"}),
            ("æ¨™é¡Œï¼š[æ¨™çš„] 2330 å°ç©é›»åˆ†æ", {"title": "[æ¨™çš„] 2330 å°ç©é›»åˆ†æ", "category": "æ¨™çš„"}),
            ("Re: [è«‹ç›Š] æ–°æ‰‹å•é¡Œ", {"title": "Re: [è«‹ç›Š] æ–°æ‰‹å•é¡Œ", "category": "è«‹ç›Š"}),
            ("æ²’æœ‰åˆ†é¡çš„æ¨™é¡Œ", {"title": "æ²’æœ‰åˆ†é¡çš„æ¨™é¡Œ", "category": None}),
        ]

        for content, expected in test_cases:
            result = parser_service._parse_title(content, {})
            if expected["title"]:
                assert result["title"] == expected["title"]
                assert result["category"] == expected["category"]
            else:
                assert result is None

    def test_extract_category_from_title(self, parser_service: ParserService):
        """Test category extraction from titles."""
        test_cases = [
            ("[å¿ƒå¾—] æŠ•è³‡åˆ†äº«", "å¿ƒå¾—"),
            ("[æ¨™çš„] è‚¡ç¥¨åˆ†æ", "æ¨™çš„"),
            ("[è«‹ç›Š] æ±‚åŠ©å•é¡Œ", "è«‹ç›Š"),
            ("[é–’èŠ] éš¨ä¾¿èŠèŠ", "é–’èŠ"),
            ("[æ–°è] é‡è¦æ¶ˆæ¯", "æ–°è"),
            ("æ²’æœ‰åˆ†é¡", None),
            ("[è‡ªå®šç¾©åˆ†é¡] æ¸¬è©¦", "è‡ªå®šç¾©åˆ†é¡"),
        ]

        for title, expected_category in test_cases:
            category = parser_service._extract_category_from_title(title)
            assert category == expected_category

    def test_parse_author_patterns(self, parser_service: ParserService):
        """Test author parsing with different patterns."""
        test_cases = [
            ("ä½œè€…: test_user", "test_user"),
            ("Author: english_user", "english_user"),
            ("ä½œè€…ï¼šuser_with_info (å­¸ç”Ÿ)", "user_with_info"),
            ("â€» ç™¼ä¿¡ç«™: æ‰¹è¸¢è¸¢å¯¦æ¥­åŠ(ptt.cc), ä¾†è‡ª: author_from_station", "author_from_station"),
            ("no author info", None),
        ]

        for content, expected_author in test_cases:
            author = parser_service._parse_author(content, {})
            if expected_author:
                assert author == expected_author

    def test_parse_time_string_formats(self, parser_service: ParserService):
        """Test parsing different time string formats."""
        test_cases = [
            ("Mon Sep 25 10:30:00 2024", True),
            ("2024/09/25 10:30:00", True),
            ("09/25/2024 10:30:00", True),
            ("2024-09-25 10:30:00", True),
            ("25/09/2024 10:30", True),
            ("2024/09/25", True),
            ("invalid_time", False),
            ("", False),
        ]

        for time_str, should_parse in test_cases:
            result = parser_service._parse_time_string(time_str)
            if should_parse:
                assert isinstance(result, datetime)
            else:
                assert result is None

    def test_clean_article_content(self, parser_service: ParserService):
        """Test article content cleaning."""
        dirty_content = """æ–‡ç« æ­£æ–‡å…§å®¹

é€™è£¡æ˜¯æ­£å¸¸å…§å®¹ã€‚

â€» ç™¼ä¿¡ç«™: æ‰¹è¸¢è¸¢å¯¦æ¥­åŠ(ptt.cc)
â€» æ–‡ç« ç¶²å€: https://example.com
â€» ç·¨è¼¯: user123

æ¨ user1: æ¨æ¨
â†’ user2: åŒæ„
å™“ user3: ä¸åŒæ„
09/25 10:30

æ›´å¤šæ­£å¸¸å…§å®¹ã€‚"""

        cleaned = parser_service._clean_article_content(dirty_content)

        # Should remove system messages
        assert "â€» ç™¼ä¿¡ç«™" not in cleaned
        assert "â€» æ–‡ç« ç¶²å€" not in cleaned
        assert "â€» ç·¨è¼¯" not in cleaned

        # Should remove comments
        assert "æ¨ user1" not in cleaned
        assert "â†’ user2" not in cleaned
        assert "å™“ user3" not in cleaned

        # Should keep normal content
        assert "æ–‡ç« æ­£æ–‡å…§å®¹" in cleaned
        assert "é€™è£¡æ˜¯æ­£å¸¸å…§å®¹" in cleaned
        assert "æ›´å¤šæ­£å¸¸å…§å®¹" in cleaned

        # Should normalize whitespace
        assert not cleaned.startswith(" ")
        assert not cleaned.endswith(" ")

    def test_parse_board_page(self, parser_service: ParserService, sample_board_response: Dict[str, Any]):
        """Test board page parsing for article links."""
        articles = parser_service.parse_board_page(sample_board_response)

        assert len(articles) >= 2

        # Check first article
        first_article = articles[0]
        assert "url" in first_article
        assert "title" in first_article
        assert "https://www.ptt.cc/bbs/Stock/" in first_article["url"]
        assert first_article["title"]

    def test_parse_board_page_empty(self, parser_service: ParserService):
        """Test parsing empty board page."""
        empty_response = {
            "success": True,
            "data": {
                "markdown": "",
                "links": []
            }
        }

        articles = parser_service.parse_board_page(empty_response)
        assert articles == []

    def test_validate_article_data_valid(self, parser_service: ParserService):
        """Test article data validation with valid data."""
        valid_data = {
            "title": "[å¿ƒå¾—] æ¸¬è©¦æ¨™é¡Œ",
            "author": "test_user",
            "content": "é€™æ˜¯æœ‰è¶³å¤ é•·åº¦çš„æ–‡ç« å…§å®¹ï¼Œç”¨ä¾†æ¸¬è©¦é©—è­‰åŠŸèƒ½æ˜¯å¦æ­£å¸¸é‹ä½œã€‚",
            "category": "å¿ƒå¾—",
            "board": "Stock",
            "publish_date": datetime.now(),
        }

        assert parser_service.validate_article_data(valid_data) is True

    def test_validate_article_data_invalid(self, parser_service: ParserService):
        """Test article data validation with invalid data."""
        # Missing required field
        invalid_data_missing = {
            "title": "[å¿ƒå¾—] æ¸¬è©¦æ¨™é¡Œ",
            "author": "",  # Empty author
            "content": "å…§å®¹",
        }
        assert parser_service.validate_article_data(invalid_data_missing) is False

        # Content too short
        invalid_data_short = {
            "title": "[å¿ƒå¾—] æ¸¬è©¦æ¨™é¡Œ",
            "author": "test_user",
            "content": "çŸ­",  # Too short
        }
        assert parser_service.validate_article_data(invalid_data_short) is False

        # Empty title
        invalid_data_title = {
            "title": "",  # Empty title
            "author": "test_user",
            "content": "é€™æ˜¯æœ‰è¶³å¤ é•·åº¦çš„å…§å®¹",
        }
        assert parser_service.validate_article_data(invalid_data_title) is False

    def test_extract_keywords(self, parser_service: ParserService):
        """Test keyword extraction from content."""
        content = """é€™æ˜¯ä¸€ç¯‡é—œæ–¼æŠ•è³‡è‚¡ç¥¨çš„æ–‡ç« ã€‚
        å°ç©é›»æ˜¯å¾ˆå¥½çš„æŠ•è³‡æ¨™çš„ï¼Œå»ºè­°å¤§å®¶å¯ä»¥è€ƒæ…®æŠ•è³‡å°ç©é›»ã€‚
        è‚¡ç¥¨å¸‚å ´æœ€è¿‘è¡¨ç¾ä¸éŒ¯ï¼ŒæŠ•è³‡æ©Ÿæœƒå¾ˆå¤šã€‚
        æŠ•è³‡éœ€è¦è¬¹æ…ï¼Œå»ºè­°åšå¥½é¢¨éšªæ§åˆ¶ã€‚"""

        keywords = parser_service.extract_keywords(content, max_keywords=5)

        assert len(keywords) <= 5
        assert "æŠ•è³‡" in keywords  # Should be high frequency
        assert "å°ç©é›»" in keywords
        assert "è‚¡ç¥¨" in keywords

        # Test with empty content
        empty_keywords = parser_service.extract_keywords("", max_keywords=5)
        assert empty_keywords == []

    def test_get_content_summary(self, parser_service: ParserService):
        """Test content summary generation."""
        # Long content
        long_content = "é€™æ˜¯ä¸€å€‹å¾ˆé•·çš„æ–‡ç« å…§å®¹ã€‚" * 50
        summary = parser_service.get_content_summary(long_content, max_length=50)

        assert len(summary) <= 53  # 50 + "..."
        assert summary.endswith("...")

        # Short content
        short_content = "é€™æ˜¯çŸ­å…§å®¹"
        summary = parser_service.get_content_summary(short_content, max_length=50)
        assert summary == short_content

        # Content with sentence breaks
        sentence_content = "ç¬¬ä¸€å¥è©±ã€‚ç¬¬äºŒå¥è©±ã€‚ç¬¬ä¸‰å¥è©±å¾ˆé•·å¾ˆé•·å¾ˆé•·å¾ˆé•·å¾ˆé•·å¾ˆé•·å¾ˆé•·ã€‚"
        summary = parser_service.get_content_summary(sentence_content, max_length=20)
        assert summary.endswith("ã€‚") or summary.endswith("...")

        # Empty content
        empty_summary = parser_service.get_content_summary("", max_length=50)
        assert empty_summary == ""

    def test_parser_error_handling(self, parser_service: ParserService):
        """Test parser error handling with malformed data."""
        # Malformed response structure
        malformed_response = {
            "success": True,
            "invalid_structure": "test"
        }

        url = "https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html"
        result = await parser_service.parse_article(malformed_response, url)
        assert result is None

        # Response with success=False
        failed_response = {
            "success": False,
            "data": {
                "markdown": "content",
                "metadata": {}
            }
        }

        result = await parser_service.parse_article(failed_response, url)
        # Should still try to parse if data exists

    def test_parse_special_characters(self, parser_service: ParserService):
        """Test parsing content with special characters."""
        special_content = """æ¨™é¡Œï¼š[å¿ƒå¾—] ç‰¹æ®Šå­—ç¬¦æ¸¬è©¦ ğŸš€ğŸ“ˆ

ä½œè€…: test_user
æ™‚é–“: 2024/09/25 10:30:00

é€™æ˜¯åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å…§å®¹ï¼š
â€¢ é …ç›®ä¸€
â€¢ é …ç›®äºŒ â˜…â˜…â˜…
â†’ ç®­é ­ç¬¦è™Ÿ
â€» ç‰¹æ®Šæ¨™è¨˜

ä¸­æ–‡å­—ç¬¦ï¼šä½ å¥½ä¸–ç•Œ
è‹±æ–‡å­—ç¬¦ï¼šHello World
æ•¸å­—ï¼š12345
ç¬¦è™Ÿï¼š!@#$%^&*()"""

        response = {
            "success": True,
            "data": {
                "markdown": special_content,
                "metadata": {}
            }
        }

        url = "https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html"
        result = await parser_service.parse_article(response, url)

        assert result is not None
        assert "ä½ å¥½ä¸–ç•Œ" in result["content"]
        assert "Hello World" in result["content"]
        assert result["author"] == "test_user"

    async def test_parse_article_with_metadata_priority(self, parser_service: ParserService):
        """Test that metadata has priority over content parsing."""
        response = {
            "success": True,
            "data": {
                "markdown": "æ¨™é¡Œï¼š[éŒ¯èª¤] é€™æ˜¯éŒ¯èª¤çš„æ¨™é¡Œ\nä½œè€…: wrong_author",
                "metadata": {
                    "title": "[å¿ƒå¾—] æ­£ç¢ºçš„æ¨™é¡Œ",
                    "author": "correct_author",
                    "publishTime": "2024/09/25 10:30:00"
                }
            }
        }

        url = "https://www.ptt.cc/bbs/Stock/M.1234567890.A.123.html"
        result = await parser_service.parse_article(response, url)

        assert result is not None
        # Should use metadata values
        assert result["title"] == "[å¿ƒå¾—] æ­£ç¢ºçš„æ¨™é¡Œ"
        assert result["author"] == "correct_author"
        assert result["category"] == "å¿ƒå¾—"